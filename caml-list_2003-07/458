Received: (from majordomo@localhost) by pauillac.inria.fr (8.7.6/8.7.3) id CAA20223; Wed, 16 Jul 2003 02:23:54 +0200 (MET DST)
X-Authentication-Warning: pauillac.inria.fr: majordomo set sender to owner-caml-list@pauillac.inria.fr using -f
Received: from nez-perce.inria.fr (nez-perce.inria.fr [192.93.2.78]) by pauillac.inria.fr (8.7.6/8.7.3) with ESMTP id CAA28792 for <caml-list@pauillac.inria.fr>; Wed, 16 Jul 2003 02:23:53 +0200 (MET DST)
Received: from mclean.mail.mindspring.net (mclean.mail.mindspring.net [207.69.200.57])
	by nez-perce.inria.fr (8.11.1/8.11.1) with ESMTP id h6G0NqT16120
	for <caml-list@inria.fr>; Wed, 16 Jul 2003 02:23:52 +0200 (MET DST)
Received: from user-0cev2rh.cable.mindspring.com ([24.239.139.113] helo=[192.168.0.3])
	by mclean.mail.mindspring.net with esmtp (Exim 3.33 #1)
	id 19ca5H-0008Pg-00
	for caml-list@inria.fr; Tue, 15 Jul 2003 20:23:51 -0400
Subject: Re: [Caml-list] ocaml on supercomputer?
From: "Yaron M. Minsky" <yminsky@cs.cornell.edu>
To: Caml List <caml-list@inria.fr>
In-Reply-To: <Pine.GSO.4.21.0307150853580.20153-100000@moussor.isi.edu>
References: <Pine.GSO.4.21.0307150853580.20153-100000@moussor.isi.edu>
Content-Type: text/plain
Organization: Cornell University
Message-Id: <1058315029.10355.18.camel@dragonfly.localdomain>
Mime-Version: 1.0
X-Mailer: Ximian Evolution 1.2.2 (1.2.2-5) 
Date: 15 Jul 2003 20:23:50 -0400
Content-Transfer-Encoding: 7bit
X-Loop: caml-list@inria.fr
X-Spam: no; 0.00; yaron:01 minsky:01 yminsky:01 cornell:01 caml-list:01 mpi:01 functor:01 parallelize:01 props:99 threads:01 exploited:01 bug:01 faq:01 beginner's:01 beginners:01 
Sender: owner-caml-list@pauillac.inria.fr
Precedence: bulk

I'll second that.  I've used ocaml to great effect on my tiny little
beowulf (6 nodes) via the MPI bindings.  Not only was I able to easily
MPI-ify my code, I was able to write a clean little functor that could
be used to parallelize any bag-of-jobs style parallel task in just a few
lines of code.

So, props to ocaml and Xavier.

y

On Tue, 2003-07-15 at 12:02, Hal Daume III wrote:
> > OCaml threads do not exploit shared-memory multiprocessing --
> > basically, all threads interleave their execution, hence multiple
> > processors are not exploited.  Your best bet is MPI or PVM.  Both have
> > bindings for OCaml.
> 
> I thought I'd just stick in my own props for the Ocaml MPI bindings.  I
> had an ~11k line ocaml program which I ported to MPI.  It only required
> 500 or so more lines of code to MPI-ify it (with minor restructuring so
> these parts could be separated out).
> 
> It now runs on our supercomputer (56th faster computer in the world,
> according to top500.org) on anywhere from 10 to 170 nodes (IBM
> Netfinity Cluster P4 Xeon 2 GHz - Myrinet/ 512), and performs incredibly
> well.
> 
> I am *very* happing with these bindings and would like to formally thank
> Xavier for writing them :).
> 
> Best of luck.
> 
>  - Hal
> 
> 
> 
> -------------------
> To unsubscribe, mail caml-list-request@inria.fr Archives: http://caml.inria.fr
> Bug reports: http://caml.inria.fr/bin/caml-bugs FAQ: http://caml.inria.fr/FAQ/
> Beginner's list: http://groups.yahoo.com/group/ocaml_beginners
-- 
|--------/            Yaron M. Minsky              \--------|
|--------\ http://www.cs.cornell.edu/home/yminsky/ /--------|

Open PGP --- KeyID B1FFD916 (new key as of Dec 4th)
Fingerprint: 5BF6 83E1 0CE3 1043 95D8 F8D5 9F12 B3A9 B1FF D916



-------------------
To unsubscribe, mail caml-list-request@inria.fr Archives: http://caml.inria.fr
Bug reports: http://caml.inria.fr/bin/caml-bugs FAQ: http://caml.inria.fr/FAQ/
Beginner's list: http://groups.yahoo.com/group/ocaml_beginners

