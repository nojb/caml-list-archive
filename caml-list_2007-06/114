Return-Path: <bhurt@spnz.org>
X-Spam-Checker-Version: SpamAssassin 3.1.3 (2006-06-01) on yquem.inria.fr
X-Spam-Level: 
X-Spam-Status: No, score=0.0 required=5.0 tests=none autolearn=disabled 
	version=3.1.3
X-Original-To: caml-list@yquem.inria.fr
Delivered-To: caml-list@yquem.inria.fr
Received: from concorde.inria.fr (concorde.inria.fr [192.93.2.39])
	by yquem.inria.fr (Postfix) with ESMTP id 96C93BC0A
	for <caml-list@yquem.inria.fr>; Wed,  6 Jun 2007 01:53:04 +0200 (CEST)
Received: from bsd4.nyct.net (mail-out8.nyct.net [216.139.141.8])
	by concorde.inria.fr (8.13.6/8.13.6) with ESMTP id l55Nr3RR023468
	(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-SHA bits=256 verify=NO)
	for <caml-list@inria.fr>; Wed, 6 Jun 2007 01:53:04 +0200
Received: from [192.168.42.2] (adsl-216-139-154-19.nyct.net [216.139.154.19])
	by bsd4.nyct.net (8.13.4/8.13.4) with ESMTP id l55Nqt1W021469;
	Tue, 5 Jun 2007 19:52:57 -0400 (EDT)
	(envelope-from bhurt@spnz.org)
Date: Tue, 5 Jun 2007 19:58:31 -0400 (EDT)
From: Brian Hurt <bhurt@spnz.org>
X-X-Sender: bhurt@localhost
To: Jon Harrop <jon@ffconsultancy.com>
Cc: Caml List <caml-list@inria.fr>
Subject: Re: [Caml-list] We should all be forking
In-Reply-To: <200706051913.13481.jon@ffconsultancy.com>
Message-ID: <Pine.LNX.4.64.0706051951020.6016@localhost>
References: <200706051913.13481.jon@ffconsultancy.com>
MIME-Version: 1.0
Content-Type: TEXT/PLAIN; charset=US-ASCII; format=flowed
X-Miltered: at concorde with ID 4665F75F.000 by Joe's j-chkmail (http://j-chkmail . ensmp . fr)!
X-Spam: no; 0.00; ocaml:01 jocaml:01 algebra:01 model:01 subset:01 jocaml:01 2007,:98 revelation:98 soup:98 wrote:01 caml-list:01 tracing:01 linear:02 vanilla:03 concurrent:03 



On Tue, 5 Jun 2007, Jon Harrop wrote:

>
> Following on from our "why not fork" discussion, here is my most elegant
> concurrent ray tracer written in vanilla OCaml.
>
> This program simply runs four processes (forking off three) in parallel to
> improve performance when 2-4 CPUs are available (increase "d" if you have >4
> CPUs).
>
> This isn't as sophisticated as the JoCaml version but it does double
> performance (taking the time down from 4s to 2s) on my dual-core machine,
> making it faster than any language that uses a concurrent GC. I don't know
> about you guys, but this is a complete revelation for me!

This actually doesn't surprise me.  Big linear algebra problems- like ray 
tracing- are almost embarassingly parallel.  This is why the supercomputer 
market died a decade and a half ago- it was just too easy to take the 
problems supercomputers were designed to handle and spread them out over 
an cluster of workstations or pcs.  What needs to be shared in the ray 
tracing example?  The model, obviously.  And the results have to be 
collected.  And what subset of the problem (which collection of rays) need 
to be worked on.  I note that the big-iron database machine (aka 
mainframe) market is alive and well.  Some problems don't parallelize 
quite so easily.

My point here is to caution against making too much soup from this lone 
oyster.  Simply because this program, and a large class of other programs 
like it, parallelize easily, doesn't mean all will.

On the other hand, for programs that do parallelize this way, JoCaml looks 
like a wonderful gift.

Brian

