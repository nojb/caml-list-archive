Return-Path: <hmf@inescporto.pt>
X-Original-To: caml-list@yquem.inria.fr
Delivered-To: caml-list@yquem.inria.fr
Received: from mail4-relais-sop.national.inria.fr (mail4-relais-sop.national.inria.fr [192.134.164.105])
	by yquem.inria.fr (Postfix) with ESMTP id ACE62BBAF
	for <caml-list@yquem.inria.fr>; Sat, 13 Mar 2010 16:37:36 +0100 (CET)
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: Av8BAGxAm0vVhjEXkGdsb2JhbACbBwEBAQEJCQwHEwMfuFmEewQ
X-IronPort-AV: E=Sophos;i="4.49,632,1262559600"; 
   d="scan'208";a="58799412"
Received: from ihsmtp01voda.lis.interhost.com (HELO ihsmtp01cons.lis.interhost.com) ([213.134.49.23])
  by mail4-smtp-sop.national.inria.fr with ESMTP; 13 Mar 2010 16:37:36 +0100
Received: from [192.168.1.64] ([95.136.106.136]) by ihsmtp01cons.lis.interhost.com with Microsoft SMTPSVC(6.0.3790.3959);
	 Sat, 13 Mar 2010 15:37:35 +0000
Message-ID: <4B9BB13F.9080506@inescporto.pt>
Date: Sat, 13 Mar 2010 15:37:35 +0000
From: Hugo Ferreira <hmf@inescporto.pt>
User-Agent: Thunderbird 2.0.0.23 (X11/20090817)
MIME-Version: 1.0
To: Richard Jones <rich@annexia.org>
Cc: caml-list@yquem.inria.fr
Subject: Re: [Caml-list] Shared memory parallel application: kernel threads
References: <4B9A2BCB.3040607@inescporto.pt>	<20100313135623.GA17113@annexia.org>	<4B9BA14F.2030805@inescporto.pt> <20100313151039.GA16796@annexia.org>
In-Reply-To: <20100313151039.GA16796@annexia.org>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-OriginalArrivalTime: 13 Mar 2010 15:37:35.0705 (UTC) FILETIME=[1AC59C90:01CAC2C3]
X-Spam: no; 0.00; model:01 model:01 nodes:01 read-only:01 threads:01 wrote:01 wrote:01 caml-list:01 data:02 data:02 kernel:02 suggestion:03 seems:03 experiments:03 mpi:04 

Richard Jones wrote:
> On Sat, Mar 13, 2010 at 02:29:35PM +0000, Hugo Ferreira wrote:
>> I will be using a single 8-CPU machine for the experiments.
>> For the problem at hand shared the memory model seems to be
>> a better fit than messaging.
> 
> I've not actually tried it, but I bet you can use a hybrid model --
> Use MPI as an easy way to spread the jobs over the nodes and for
> coordinating the processes, then have each process open a shared
> Ancient file (backed by NFS) for the read-only data.
>

I figure I will need some form of messaging to coordinate the jobs.
The problem however is that the jobs will initially generate large
amounts of data. This data is progressively "merged" and reduced.
I don't think sending messages is appropriate. At least not in
the initial stages. I will have to experiment.

Thanks for the suggestion,
Hugo F.


> Rich.
> 

