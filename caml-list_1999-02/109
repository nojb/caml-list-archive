Received: (from weis@localhost) by pauillac.inria.fr (8.7.6/8.7.3) id RAA22257 for caml-redistribution; Thu, 25 Feb 1999 17:40:25 +0100 (MET)
Received: from concorde.inria.fr (concorde.inria.fr [192.93.2.39]) by pauillac.inria.fr (8.7.6/8.7.3) with ESMTP id NAA24751 for <caml-list@pauillac.inria.fr>; Thu, 25 Feb 1999 13:10:32 +0100 (MET)
Received: from pauillac.inria.fr (pauillac.inria.fr [128.93.11.35])
	by concorde.inria.fr (8.8.7/8.8.7) with ESMTP id NAA04818;
	Thu, 25 Feb 1999 13:10:27 +0100 (MET)
Received: (from xleroy@localhost) by pauillac.inria.fr (8.7.6/8.7.3) id NAA04401; Thu, 25 Feb 1999 13:10:27 +0100 (MET)
Message-ID: <19990225131027.37364@pauillac.inria.fr>
Date: Thu, 25 Feb 1999 13:10:27 +0100
From: Xavier Leroy <Xavier.Leroy@inria.fr>
To: Shyjan Mahamud <mahamud@marr.ius.cs.cmu.edu>, caml-list@inria.fr
Subject: Re: bug in floating point implementation ?
References: <199902250043.BAA21786@nez-perce.inria.fr>
Mime-Version: 1.0
Content-Type: text/plain; charset=us-ascii
X-Mailer: Mutt 0.89.1
In-Reply-To: <199902250043.BAA21786@nez-perce.inria.fr>; from Shyjan Mahamud on Wed, Feb 24, 1999 at 07:43:05PM -0500
Sender: weis

> i'm new to CAML, so i'm not sure if this is a known issue.
> is there a known bug or difference in the implementation of floating
> point arithmetic between the toplevel and that for the standalone
> compiled version. i've run the same exact function from both the
> toplevel and a standalone program. the numbers come out slightly
> different.

The toplevel and the bytecode compiler (ocamlc) should give exactly
the same results, because they use the same bytecode compiler, virtual
machine and C primitives.

The native-code compiler (ocamlopt) generates in-line assembly code
for floating-point operations, of course, and also has various
unboxing strategies that are not found in ocamlc and in the toplevel.

On all architectures except the Intel x86, the ocamlopt tricks
shouldn't make any differences, because the same floating-point format
(IEEE double) is used everywhere.

The Intel x86 has an interesting quirk: it computes internally in
extended precision (80 bits), and rounds to double precision (64 bits)
only when storing a result in memory.  This means that in a piece of
code such as

        let x = a * b + c

the virtual machine will compute a * b, round it (by storing it in
memory), add c, and round the result.  While the native-code compiler
will compute a * b, keep the result in extended precision in the top
float register, then add c, then round the result.

In extreme cases (badly conditioned algorithm, computation of errors),
you may thus get different results.

(Similar problems plague all x86 compilers.  It's really bad for Java,
which specifies that all computations must be done in 64 bits.)

If you don't think this explains your problem (e.g. you see the same
discrepancies on other processors), please send me a complete program
that reproduces the problem and I'll look at it.

- Xavier Leroy



